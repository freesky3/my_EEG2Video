{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a04240",
   "metadata": {},
   "source": [
    "This file is used to train EEG embedding model, which transforms EEG signals into a low-dimensional semantic representation.\n",
    "\n",
    "To get the ground truth for semantic representation, We first use gemini-2.5-flash to transform  video to descriptive text. Then we use \"openai/clip-vit-large-patch14\" to transform text into embedding vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e93bf",
   "metadata": {},
   "source": [
    "## CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ea94ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"eeg_data_path\": \"data\\\\PSD_DE\\\\imaging\", # or \"data\\\\PSD_DE\\\\watching\"\n",
    "    \"text_embedding_path\": \"data\\\\metadata\\\\text_embedding.pt\",\n",
    "    \"save_checkpoint_path\": \"checkpoints\\\\eeg_embedding\",\n",
    "\n",
    "    \"seed\": 42,\n",
    "    \"train_valid\": [0.8, 0.2], \n",
    "    \"batch_size\": 32, \n",
    "    \"num_workers\": 0,\n",
    "\n",
    "    \"epochs\": 200, \n",
    "    \"learning_rate\": 5e-4, \n",
    "    \"valid_steps\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cbcb1",
   "metadata": {},
   "source": [
    "## Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "217de68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets random seeds for reproducibility across all libraries.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed to use for all random number generators.\n",
    "        cudnn_deterministic (bool): If True, sets `torch.backends.cudnn.deterministic`\n",
    "                                    to True. This can slow down training but ensures\n",
    "                                    reproducibility for convolutional operations.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cd2ef",
   "metadata": {},
   "source": [
    "## Define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "792d0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGTextDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for EEG and corresponding text embeddings.\n",
    "\n",
    "    Args:\n",
    "        eeg (np.ndarray): A numpy array of EEG data, with shape\n",
    "                          (n_samples, n_features).\n",
    "        text (torch.Tensor): A torch tensor of text embeddings, with shape\n",
    "                             (n_samples, n_embedding_dim).\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg: np.ndarray, text: torch.Tensor):\n",
    "        self.eeg = eeg\n",
    "        self.text = text\n",
    "        self.len = eeg.shape[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, item: int) -> tuple[np.ndarray, torch.Tensor]:\n",
    "        return self.eeg[item], self.text[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd63dd",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6193136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def prepare_dataloader(eeg_data_path: str, text_embed_path: str,\n",
    "                       batch_size: int, num_workers: int):\n",
    "    \"\"\"Loads, preprocesses, and prepares the EEG and Text data.\n",
    "\n",
    "    This function handles:\n",
    "    1. Loading the raw EEG data.\n",
    "    2. Selecting specific trials based on `gt_label` and `chosen_labels`.\n",
    "    3. Loading corresponding text embeddings.\n",
    "    4. Normalizing the EEG data using StandardScaler.\n",
    "    5. Creating a DataLoader for training.\n",
    "\n",
    "    Args:\n",
    "        eeg_data_path (str): Path to the EEG numpy file.\n",
    "        text_embed_path_template (str): A format string for the path to text\n",
    "                                        embedding files, e.g., 'path/to/block{i}.pt'.\n",
    "        gt_label (np.ndarray): A ground truth label matrix to find trial indices.\n",
    "        chosen_labels (list[int]): A list of class labels to include.\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A DataLoader for the prepared training data.\n",
    "    \"\"\"\n",
    "    print(\"Preparing data...\")\n",
    "    eeg_data = []\n",
    "    for file in os.listdir(eeg_data_path):\n",
    "        file_path = os.path.join(eeg_data_path, file)\n",
    "        eeg_data.append(np.load(file_path))\n",
    "    eeg_data = np.stack(eeg_data, axis=0)\n",
    "    print(f\"Loaded EEG data with shape: {eeg_data.shape}\") # (60, 2, 5, 50, 62, 5)\n",
    "\n",
    "\n",
    "    # Process each session's EEG data\n",
    "    eeg = rearrange(eeg_data, 'a b c d e f -> (a b c d) (e f)') # shape(60*2*5*50, 62*5)\n",
    "    \n",
    "    # Process each session's text data\n",
    "    text = torch.load(text_embed_path) # shape(250, 77, 768)\n",
    "    text = repeat(text, 'a b c -> (num a) (b c)', num = eeg_data.shape[0]*2) # shape(60*2*250, 59136)\n",
    "\n",
    "    # Normalize EEG data\n",
    "    normalize = preprocessing.StandardScaler()\n",
    "    eeg = normalize.fit_transform(eeg)\n",
    "    print(f\"Final EEG data shape: {eeg.shape}\")\n",
    "    print(f\"Final Text embedding shape: {text.shape}\")\n",
    "\n",
    "    dataset = EEGTextDataset(eeg, text)\n",
    "    trainset, validset = random_split(dataset, CONFIG[\"train_valid\"])\n",
    "    train_loader = DataLoader(\n",
    "        trainset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        validset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab6478",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5d43520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EEG_Embedding(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron model to map EEG signals to text embedding space.\n",
    "\n",
    "    This model takes flattened EEG data and projects it into a high-dimensional\n",
    "    space matching the dimensions of CLIP's text embeddings (77 * 768 = 59136).\n",
    "\n",
    "    Architecture:\n",
    "        - Input: EEG features (310 dimensions)\n",
    "        - Hidden layers: 1000 -> 10000 -> 1000 -> 1000 dimensions\n",
    "        - Output: 59136 dimensions (77 * 768, matching CLIP text embeddings)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(EEG_Embedding, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(310, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Add dropout for regularization\n",
    "            nn.Linear(1000, 10000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(10000, 1000),  # Fixed: was 1000 -> 1000, should be 10000 -> 1000\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1000, 77 * 768)  # Output dimension: 59136\n",
    "        )\n",
    "\n",
    "    def forward(self, eeg: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            eeg (torch.Tensor): A batch of EEG data with shape (batch_size, 310).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The predicted text embeddings with shape\n",
    "                          (batch_size, 77 * 768).\n",
    "        \"\"\"\n",
    "        eeg_embeddings = self.mlp(eeg)\n",
    "        return eeg_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59e488",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24df20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(batch, model, criterion, device): \n",
    "    \"\"\"Compute loss for a batch of EEG and text data.\n",
    "    \n",
    "    Args:\n",
    "        batch: Tuple of (eeg_data, text_embeddings) from DataLoader\n",
    "        model: The EEG embedding model\n",
    "        criterion: Loss function (e.g., MSE)\n",
    "        device: Device to run computation on\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Computed loss value\n",
    "    \"\"\"\n",
    "    eeg_data, text_embeddings = batch\n",
    "    eeg_data = eeg_data.float().to(device)  # Convert to float and move to device\n",
    "    text_embeddings = text_embeddings.float().to(device)\n",
    "    \n",
    "    # Forward pass through model\n",
    "    predicted_embeddings = model(eeg_data)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(predicted_embeddings, text_embeddings)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7cff",
   "metadata": {},
   "source": [
    "## Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2f265b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def validate_model(data_loader, model, criterion, device): \n",
    "    \"\"\"Validate the model on the validation set.\n",
    "    \n",
    "    Args:\n",
    "        data_loader: Validation DataLoader\n",
    "        model: The model to validate\n",
    "        criterion: Loss function\n",
    "        device: Device to run computation on\n",
    "        \n",
    "    Returns:\n",
    "        float: Average validation loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    pbar = tqdm(total=len(data_loader.dataset), ncols=0, desc='Valid')\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            loss = loss_fn(batch, model, criterion, device)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            pbar.update(data_loader.batch_size)\n",
    "            pbar.set_postfix(loss=f\"{running_loss / (i+1):.4f}\")\n",
    "    \n",
    "    pbar.close()\n",
    "    model.train()  # Set back to training mode\n",
    "\n",
    "    avg_loss = running_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefa9c7",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1125e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def main(): \n",
    "    \"\"\"Main training function.\"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    set_seed(CONFIG[\"seed\"])\n",
    "\n",
    "    # Determine device to use\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader, valid_loader = prepare_dataloader(\n",
    "        CONFIG[\"eeg_data_path\"], \n",
    "        CONFIG[\"text_embedding_path\"], \n",
    "        CONFIG[\"batch_size\"], \n",
    "        CONFIG[\"num_workers\"]\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = EEG_Embedding().to(device)\n",
    "    print(f\"Model moved to {device}\")\n",
    "\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=CONFIG[\"epochs\"] * len(train_loader)\n",
    "    )\n",
    "    criterion = F.mse_loss\n",
    "    print(\"Optimizer, scheduler, and loss function initialized\")\n",
    "\n",
    "    # Training tracking variables\n",
    "    best_loss = float('inf')  # Track best validation loss instead of accuracy\n",
    "    best_state_dict = None\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(CONFIG[\"save_checkpoint_path\"], exist_ok=True)\n",
    "    print(f\"Checkpoint directory: {CONFIG['save_checkpoint_path']}\")\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    pbar = tqdm(range(CONFIG['epochs']), desc='Train', unit='epoch', dynamic_ncols=True)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training phase\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Compute loss\n",
    "            loss = loss_fn(batch, model, criterion, device)\n",
    "            batch_loss = loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += batch_loss\n",
    "\n",
    "        # Calculate average training loss for this epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        pbar.set_postfix(\n",
    "            train_loss=f\"{train_loss:.4f}\", \n",
    "            lr=f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        )\n",
    "\n",
    "        # Validation phase\n",
    "        if (epoch + 1) % CONFIG['valid_steps'] == 0:\n",
    "            valid_loss = validate_model(valid_loader, model, criterion, device)\n",
    "            print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_state_dict = model.state_dict()\n",
    "                print(f\"✅ Best validation loss updated: {best_loss:.4f}\")\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Save the best model\n",
    "    if best_state_dict is not None:\n",
    "        best_model_path = os.path.join(CONFIG[\"save_checkpoint_path\"], \"best_model.pth\")\n",
    "        torch.save(best_state_dict, best_model_path)\n",
    "        print(f\"🎉 Best model saved to {best_model_path}\")\n",
    "        print(f\"Final best validation loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"No best model was saved (validation was not performed)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e57e81",
   "metadata": {},
   "source": [
    "## Start Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08941b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Preparing data...\n",
      "Loaded EEG data with shape: (6, 2, 5, 50, 62, 5)\n",
      "Final EEG data shape: (3000, 310)\n",
      "Final Text embedding shape: torch.Size([3000, 59136])\n",
      "Model moved to cpu\n",
      "Optimizer, scheduler, and loss function initialized\n",
      "Checkpoint directory: checkpoints\\eeg_embedding\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/200 [00:11<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m# Clear gradients\u001b[39;00m\n\u001b[32m     57\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m scheduler.step()\n\u001b[32m     61\u001b[39m running_loss += batch_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\optim\\adam.py:525\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    523\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    527\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
