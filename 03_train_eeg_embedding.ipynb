{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a04240",
   "metadata": {},
   "source": [
    "This file is used to train EEG embedding model, which transforms EEG signals into a low-dimensional semantic representation.\n",
    "\n",
    "To get the ground truth for semantic representation, We first use gemini-2.5-flash to transform  video to descriptive text. Then we use \"openai/clip-vit-large-patch14\" to transform text into embedding vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e93bf",
   "metadata": {},
   "source": [
    "## CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ea94ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"eeg_data_path\": \"data\\\\PSD_DE\\\\imaging\", # or \"data\\\\PSD_DE\\\\watching\"\n",
    "    \"text_embedding_path\": \"data\\\\metadata\\\\text_embedding.pt\",\n",
    "    \"save_checkpoint_path\": \"checkpoints\\\\eeg_embedding\",\n",
    "\n",
    "    \"seed\": 42,\n",
    "    \"train_valid\": [0.8, 0.2], \n",
    "    \"batch_size\": 32, \n",
    "    \"num_workers\": 0,\n",
    "\n",
    "    \"epochs\": 200, \n",
    "    \"learning_rate\": 5e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cbcb1",
   "metadata": {},
   "source": [
    "## Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "217de68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets random seeds for reproducibility across all libraries.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed to use for all random number generators.\n",
    "        cudnn_deterministic (bool): If True, sets `torch.backends.cudnn.deterministic`\n",
    "                                    to True. This can slow down training but ensures\n",
    "                                    reproducibility for convolutional operations.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cd2ef",
   "metadata": {},
   "source": [
    "## Define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "792d0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGTextDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for EEG and corresponding text embeddings.\n",
    "\n",
    "    Args:\n",
    "        eeg (np.ndarray): A numpy array of EEG data, with shape\n",
    "                          (n_samples, n_features).\n",
    "        text (torch.Tensor): A torch tensor of text embeddings, with shape\n",
    "                             (n_samples, n_embedding_dim).\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg: np.ndarray, text: torch.Tensor):\n",
    "        self.eeg = eeg\n",
    "        self.text = text\n",
    "        self.len = eeg.shape[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, item: int) -> tuple[np.ndarray, torch.Tensor]:\n",
    "        return self.eeg[item], self.text[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd63dd",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6193136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def prepare_dataloader(eeg_data_path: str, text_embed_path: str,\n",
    "                       batch_size: int, num_workers: int):\n",
    "    \"\"\"Loads, preprocesses, and prepares the EEG and Text data.\n",
    "\n",
    "    This function handles:\n",
    "    1. Loading the raw EEG data.\n",
    "    2. Selecting specific trials based on `gt_label` and `chosen_labels`.\n",
    "    3. Loading corresponding text embeddings.\n",
    "    4. Normalizing the EEG data using StandardScaler.\n",
    "    5. Creating a DataLoader for training.\n",
    "\n",
    "    Args:\n",
    "        eeg_data_path (str): Path to the EEG numpy file.\n",
    "        text_embed_path_template (str): A format string for the path to text\n",
    "                                        embedding files, e.g., 'path/to/block{i}.pt'.\n",
    "        gt_label (np.ndarray): A ground truth label matrix to find trial indices.\n",
    "        chosen_labels (list[int]): A list of class labels to include.\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A DataLoader for the prepared training data.\n",
    "    \"\"\"\n",
    "    print(\"Preparing data...\")\n",
    "    eeg_data = []\n",
    "    for file in os.listdir(eeg_data_path):\n",
    "        file_path = os.path.join(eeg_data_path, file)\n",
    "        eeg_data.append(np.load(file_path))\n",
    "    eeg_data = np.stack(eeg_data, axis=0)\n",
    "    print(f\"Loaded EEG data with shape: {eeg_data.shape}\") # (60, 2, 5, 50, 62, 5)\n",
    "\n",
    "\n",
    "    # Process each session's EEG data\n",
    "    eeg = rearrange(eeg_data, 'a b c d e f -> (a b c d) (e f)') # shape(60*2*5*50, 62*5)\n",
    "    \n",
    "    # Process each session's text data\n",
    "    text = torch.load(text_embed_path) # shape(250, 77, 768)\n",
    "    text = repeat(text, 'a b c -> (num a) (b c)', num = eeg_data.shape[0]) # shape(60*250, 59136)\n",
    "\n",
    "    # Normalize EEG data\n",
    "    normalize = preprocessing.StandardScaler()\n",
    "    eeg = normalize.fit_transform(eeg)\n",
    "    print(f\"Final EEG data shape: {eeg.shape}\")\n",
    "    print(f\"Final Text embedding shape: {text.shape}\")\n",
    "\n",
    "    dataset = EEGTextDataset(eeg, text)\n",
    "    trainset, validset = random_split(dataset, CONFIG[\"train_valid\"])\n",
    "    train_loader = DataLoader(\n",
    "        trainset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        validset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab6478",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d43520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EEG_Embedding(nn.Module):\n",
    "    \"\"\"A simple MLP model to map EEG signals to text embedding space.\n",
    "\n",
    "    This model takes flattened EEG data and projects it into a high-dimensional\n",
    "    space matching the dimensions of CLIP's text embeddings (77 * 768).\n",
    "\n",
    "    Attributes:\n",
    "        mlp (nn.Sequential): A multi-layer perceptron consisting of linear\n",
    "                             layers and ReLU activations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(EEG_Embedding, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(310, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 10000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 77 * 768)\n",
    "        )\n",
    "\n",
    "    def forward(self, eeg: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            eeg (torch.Tensor): A batch of EEG data with shape (batch_size, 310).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The predicted text embeddings with shape\n",
    "                          (batch_size, 77 * 768).\n",
    "        \"\"\"\n",
    "        eeg_embeddings = self.mlp(eeg)\n",
    "        return eeg_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59e488",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24df20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(input, target, criterion, device): \n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "    loss = criterion(input, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7cff",
   "metadata": {},
   "source": [
    "## Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2f265b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def valid(data_loader, model, criterion, device): \n",
    "    '''Validate the model on the validation set'''\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(total = len(data_loader.dataset), ncols=0, desc='Valid')\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = loss(batch, model, criterion, device)\n",
    "            running_loss += loss.item()\n",
    "        pbar.update(data_loader.batch_size)\n",
    "        pbar.set_postfix(loss=f\"{running_loss / (i+1):.2f}\")\n",
    "    pbar.close()\n",
    "    model.train()\n",
    "\n",
    "    return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefa9c7",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1125e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def main(): \n",
    "    set_seed(CONFIG[\"seed\"])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "    train_loader, valid_loader = prepare_dataloader(CONFIG[\"eeg_data_path\"], CONFIG[\"text_embedding_path\"], CONFIG[\"batch_size\"], CONFIG[\"num_workers\"])\n",
    "\n",
    "    model = EEG_Embedding().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"] * len(train_loader))\n",
    "    criterion = F.mse_loss\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_state_dict = None\n",
    "\n",
    "    pbar = tqdm(range(CONFIG['epochs']), desc='Train', unit='epoch', dynamic_ncols=True)\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            loss = loss(batch, model, criterion, device)\n",
    "            batch_loss = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += batch_loss\n",
    "\n",
    "        train_loss = running_loss/len(train_loader)\n",
    "        pbar.set_postfix(train_loss=train_loss, train_acc=1-train_loss)\n",
    "\n",
    "        if (epoch + 1) % CONFIG['valid_steps'] == 0:\n",
    "            valid_loss = valid(valid_loader, model, criterion, device)\n",
    "            valid_acc = 1-valid_loss\n",
    "            pbar.write(f\"[Info]: Valid acc: {valid_acc:.4f}\")\n",
    "            if valid_acc > best_accuracy:\n",
    "                best_accuracy = valid_acc\n",
    "                best_state_dict = model.state_dict()\n",
    "                pbar.write(f\"[Info]: 😄 Best acc updated: {best_accuracy:.4f}\")\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    torch.save(best_state_dict, os.path.join(CONFIG[\"save_path\"], \"best_model.pth\"))\n",
    "    print(\"=\"*50, f\"\\n[Info]: Best model saved to {os.path.join(CONFIG['save_path'], 'best_model.pth')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e57e81",
   "metadata": {},
   "source": [
    "## Start Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08941b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cpu now!\n",
      "Preparing data...\n",
      "Loaded EEG data with shape: (6, 2, 5, 50, 62, 5)\n",
      "Final EEG data shape: (3000, 310)\n",
      "Final Text embedding shape: torch.Size([1500, 59136])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:116] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2365440000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Info]: Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m now!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m train_loader, valid_loader = prepare_dataloader(CONFIG[\u001b[33m\"\u001b[39m\u001b[33meeg_data_path\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mtext_embedding_path\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mnum_workers\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model = \u001b[43mEEG_Embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     13\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     14\u001b[39m scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(train_loader))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mEEG_Embedding.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     14\u001b[39m     \u001b[38;5;28msuper\u001b[39m(EEG_Embedding, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m.mlp = nn.Sequential(\n\u001b[32m     16\u001b[39m         nn.Linear(\u001b[32m310\u001b[39m, \u001b[32m10000\u001b[39m),\n\u001b[32m     17\u001b[39m         nn.ReLU(),\n\u001b[32m     18\u001b[39m         nn.Linear(\u001b[32m10000\u001b[39m, \u001b[32m10000\u001b[39m),\n\u001b[32m     19\u001b[39m         nn.ReLU(),\n\u001b[32m     20\u001b[39m         nn.Linear(\u001b[32m10000\u001b[39m, \u001b[32m10000\u001b[39m),\n\u001b[32m     21\u001b[39m         nn.ReLU(),\n\u001b[32m     22\u001b[39m         nn.Linear(\u001b[32m10000\u001b[39m, \u001b[32m10000\u001b[39m),\n\u001b[32m     23\u001b[39m         nn.ReLU(),\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m77\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m768\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\app\\miniconda\\envs\\eeg_test\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:106\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.in_features = in_features\n\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.out_features = out_features\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m )\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at alloc_cpu.cpp:116] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2365440000 bytes."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
