{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b176aefb",
   "metadata": {},
   "source": [
    "This file is used to transform raw EEG data(CNT format) into numpy arrays.\n",
    "\n",
    "The output arrays will only contain the fragments during watching and imaging\n",
    "\n",
    "If you alreadly have the numpy arrays(files in ./data/sliced_eeg/watching or ./data/sliced_eeg/imaging), you can skip this step, and start with [01_extract_PSD_DE.ipyn](./01_extract_PSD_DE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a1017",
   "metadata": {},
   "source": [
    "## CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ddfd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # raw CNT data path, please put they under ./data/raw_eeg\n",
    "    \"CNT_PATH\": './data/raw_eeg', \n",
    "    # ensure the below path exists\n",
    "    \"watching_save_path\": './data/sliced_eeg/watching',\n",
    "    \"imaging_save_path\": './data/sliced_eeg/imaging', \n",
    "    \"frequency\": 200\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbaa97a",
   "metadata": {},
   "source": [
    "## Downsample and slice the EEG signal by videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "975728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "\n",
    "def downsample_data(data, downsample_rate=5):\n",
    "    if downsample_rate ==5: \n",
    "        resample_len = data.shape[1] // 5\n",
    "    elif downsample_rate == 2.5:\n",
    "        resample_len = data.shape[1]*2 // 5\n",
    "    else:\n",
    "        raise ValueError(f\"Downsample rate should be 2.5 or 5\")\n",
    "\n",
    "    resampled_data = resample(data, resample_len, axis=1)\n",
    "    return resampled_data\n",
    "\n",
    "def slice_by_video(raw, downsample_rate, max_length=505000):\n",
    "    '''Slice the raw data by video and downsample the data.\n",
    "    Args:\n",
    "        raw: mne.Raw object\n",
    "        max_length: int, the maximum length of the data\n",
    "        downsample_rate: int, the downsample rate, ensure the data frequency is 200Hz\n",
    "    Returns:\n",
    "        slice_data: np.array, the sliced data, shape (5, 62, 505*200)\n",
    "            5: the number of videos\n",
    "            62: the number of channels\n",
    "            505*200: 505 seconds per video, data frequency is 200Hz\n",
    "    '''\n",
    "    bad_channels = ['M1', 'M2', 'VEO', 'HEO']\n",
    "    raw.drop_channels(bad_channels)\n",
    "\n",
    "    # slice by events\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "    # filter events by id\n",
    "    events = np.array([i for i in events if i[2] == 1 or i[2] == 2])\n",
    "    start_events = events[0::2, 0]\n",
    "    end_events = events[1::2, 0]\n",
    "    time_range = list(zip(start_events, end_events))\n",
    "    max_length = max_length \n",
    "    slice_data = []\n",
    "    for start, end in time_range:\n",
    "        data = raw.get_data(start=start, stop=end)\n",
    "        data = data[:, :max_length]\n",
    "        resample_data = downsample_data(data, downsample_rate)\n",
    "        slice_data.append(resample_data)\n",
    "    slice_data = np.stack(slice_data, axis=0)\n",
    "    return slice_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e4f250",
   "metadata": {},
   "source": [
    "## Slice the data by clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cbb18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_by_clip(video_segments):\n",
    "    '''Divide the video segments by clip\n",
    "    Args:\n",
    "        video_segments: np.array, the video segments, shape (5, 62, 505*200)\n",
    "    Returns:\n",
    "        watching_clip: the watching data corresponding to each video, shape is (5, 50, 62, 2*200)\n",
    "            5: 5 videos, 50: 50 clips per video, 62: 62 electrodes, 400: 2*200: 2 seconds * 200 Hz\n",
    "        imaging_clip: the imaging data corresponding to each video, shape is (5, 50, 62, 3*200)\n",
    "            5: 5 videos, 50: 50 clips per video, 62: 62 electrodes, 600: 3*200: 3 seconds * 200 Hz\n",
    "    '''\n",
    "    watching_start = np.array([i+5 for i in range(0, 500, 10)])\n",
    "    watching_range = zip(watching_start, watching_start+2)\n",
    "    imaging_start = watching_start + 4\n",
    "    imaging_range = zip(imaging_start, imaging_start+3)\n",
    "    fre = CONFIG[\"frequency\"]\n",
    "    watching_clip = []\n",
    "    for start, end in watching_range:\n",
    "        watching_clip.append(video_segments[:, :, start*fre:end*fre])\n",
    "    watching_clip = np.stack((watching_clip), axis=1)\n",
    "    imaging_clip = []\n",
    "    for start, end in imaging_range:\n",
    "        imaging_clip.append(video_segments[:, :, start*fre:end*fre])\n",
    "    imaging_clip = np.stack((imaging_clip), axis=1)\n",
    "    return watching_clip, imaging_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48174843",
   "metadata": {},
   "source": [
    "## Start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b28ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17927\\AppData\\Local\\Temp\\ipykernel_26952\\3642210849.py:7: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  cnt_data = mne.io.read_raw_cnt(cnt_file)\n",
      " 17%|█▋        | 1/6 [00:07<00:37,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:14<00:27,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2'), np.str_('255')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:20<00:20,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:27<00:13,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17927\\AppData\\Local\\Temp\\ipykernel_26952\\3642210849.py:7: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  cnt_data = mne.io.read_raw_cnt(cnt_file)\n",
      " 83%|████████▎ | 5/6 [00:33<00:06,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17927\\AppData\\Local\\Temp\\ipykernel_26952\\3642210849.py:7: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  cnt_data = mne.io.read_raw_cnt(cnt_file)\n",
      "100%|██████████| 6/6 [00:39<00:00,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== \n",
      "All files are done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "for file in tqdm(os.listdir(CONFIG[\"CNT_PATH\"])):\n",
    "    if file.endswith('.cnt'):\n",
    "        cnt_file = os.path.join(CONFIG[\"CNT_PATH\"], file)\n",
    "        cnt_data = mne.io.read_raw_cnt(cnt_file)\n",
    "        if file == 'zhangyiran_20250722_session3.cnt':\n",
    "            video_segments = slice_by_video(cnt_data, downsample_rate=2.5)\n",
    "        else:\n",
    "            video_segments = slice_by_video(cnt_data, downsample_rate=5)\n",
    "        watching_clip, imaging_clip = divide_by_clip(video_segments = video_segments)\n",
    "        np.save(os.path.join(CONFIG[\"watching_save_path\"], file.split('.')[0]+'_watching.npy'), watching_clip)\n",
    "        np.save(os.path.join(CONFIG[\"imaging_save_path\"], file.split('.')[0]+'_imaging.npy'), imaging_clip)\n",
    "\n",
    "print(\"=\"*50, \"\\nAll files are done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
